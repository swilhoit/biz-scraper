# Business Listing Scraper

A clean, modular web scraper for business listings from multiple marketplace websites using ScraperAPI.

## ğŸ“‹ Features

- **9 Marketplace Scrapers**: QuietLight, BizBuySell, BizQuest, WebsiteProperties, Flippa, EmpireFlippers, Acquire, FE International, WebsiteClosers
- **Database Storage**: SQLite with SQLAlchemy ORM (no CSV files)
- **ScraperAPI Integration**: Bypass anti-scraping measures
- **Amazon FBA Detection**: Automatic identification of Amazon FBA businesses
- **Enhanced Detail Scraping**: Fetch additional details from listing pages
- **Data Analysis Tools**: Comprehensive analytics and reporting
- **Modular Architecture**: Easy to add new sites
- **Comprehensive Data**: Price, revenue, cash flow, EBITDA, location, industry, and more
- **Automatic Deduplication**: Based on listing URL

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone the repository
git clone <your-repo-url>
cd biz-scraper-clean

# Install dependencies
pip install -r requirements.txt
```

### 2. Configuration

```bash
# Copy environment file
cp .env.example .env

# Edit .env and add your ScraperAPI key
# Get your key at: https://www.scraperapi.com/
```

### 3. Run the Scraper

```bash
# Run all sites
python main.py

# Run specific sites
python main.py --sites QuietLight BizQuest

# Limit listings per site
python main.py --max-listings 50

# Or use the runner script
./run_scraper.sh --sites QuietLight --max-listings 10
```

## ğŸ“Š Supported Sites

| Site | Success Rate | Notes |
|------|-------------|-------|
| **QuietLight** | â­â­â­â­â­ | Best performer, high-value listings ($1M-$17M) |
| **BizQuest** | â­â­â­â­ | Good for small-medium businesses |
| **WebsiteProperties** | â­â­â­â­ | Digital businesses, SaaS focused |
| **Acquire.com** | â­â­â­ | Startups and SaaS acquisitions |
| **FE International** | â­â­â­ | Premium online business broker |
| **WebsiteClosers** | â­â­â­ | Established online businesses |
| **BizBuySell** | â­â­ | Individual pages may fail (anti-scraping) |
| **Flippa** | â­â­ | JavaScript-heavy, limited success |
| **EmpireFlippers** | â­â­ | JavaScript-heavy, needs different approach |

## ğŸ—„ï¸ Database Schema

The SQLite database (`businesses.db`) stores:

- **Basic Info**: title, source_site, listing_url
- **Financials**: price, revenue, cash_flow, multiple, ebitda, inventory_value
- **Details**: location, industry, established_year, employees, website
- **Features**: seller_financing, reason_for_selling, monthly_traffic
- **Amazon FBA**: is_amazon_fba, amazon_business_type
- **Metadata**: scraped_at, updated_at, enhanced_at

## ğŸ—ï¸ Project Structure

```
biz-scraper-clean/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py          # ScraperAPI config & site definitions
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ schema.py            # SQLAlchemy models
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_scraper.py      # Abstract base class
â”‚   â”œâ”€â”€ bizbuysell_scraper.py
â”‚   â”œâ”€â”€ bizquest_scraper.py
â”‚   â”œâ”€â”€ flippa_scraper.py
â”‚   â”œâ”€â”€ quietlight_scraper.py
â”‚   â”œâ”€â”€ websiteproperties_scraper.py
â”‚   â”œâ”€â”€ empireflippers_scraper.py
â”‚   â”œâ”€â”€ acquire_scraper.py
â”‚   â”œâ”€â”€ feinternational_scraper.py
â”‚   â”œâ”€â”€ websiteclosers_scraper.py
â”‚   â””â”€â”€ detail_scraper.py    # Enhanced detail fetcher
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ amazon_detector.py   # Amazon FBA detection
â”œâ”€â”€ .env.example             # Environment template
â”œâ”€â”€ .gitignore              # Git ignore rules
â”œâ”€â”€ main.py                 # Entry point
â”œâ”€â”€ analyze_data.py         # Data analysis tool
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ run_scraper.sh         # Convenience runner
â”œâ”€â”€ test_all_sites.py      # Test suite
â””â”€â”€ README.md              # This file
```

## ğŸ” Additional Features

### Amazon FBA Detection
The scraper automatically detects Amazon FBA businesses using keyword analysis:
```bash
# Results include is_amazon_fba and amazon_business_type fields
```

### Enhanced Detail Scraping
Fetch additional details from individual listing pages:
```bash
# Enhance all listings
python -m scrapers.detail_scraper

# Enhance specific site
python -m scrapers.detail_scraper --source QuietLight --limit 10
```

### Data Analysis
Analyze scraped data with comprehensive reports:
```bash
# Full analysis report
python analyze_data.py

# Specific analyses
python analyze_data.py --amazon      # Amazon FBA analysis
python analyze_data.py --quality     # Data quality report
python analyze_data.py --high-value 1000000  # Listings over $1M
```

### Data Export
Export data to CSV for external analysis:
```bash
# Export all data
python export_data.py

# Export with filters
python export_data.py --source QuietLight
python export_data.py --amazon              # Only Amazon FBA
python export_data.py -o my_export.csv      # Custom filename
```

## ğŸ§ª Testing

```bash
# Test all sites individually
python test_all_sites.py

# This will:
# - Test search page access
# - Attempt to scrape one listing
# - Save to database
# - Report success/failure for each site
```

## ğŸ”§ Adding a New Site

1. Create a new scraper in `scrapers/` inheriting from `BaseScraper`
2. Implement `get_listing_urls()` and `scrape_listing()` methods
3. Add site config to `config/settings.py`
4. Add scraper class to `main.py`

Example:
```python
from scrapers.base_scraper import BaseScraper

class NewSiteScraper(BaseScraper):
    def get_listing_urls(self, max_pages=None):
        # Implementation
        pass
    
    def scrape_listing(self, url):
        # Implementation
        pass
```

## âš ï¸ Important Notes

- **API Limits**: ScraperAPI has request limits based on your plan
- **Rate Limiting**: The scraper includes delays to be respectful
- **Anti-Scraping**: Some sites (BizBuySell) have strong protections
- **Data Quality**: Not all fields will be available for every listing

## ğŸ“ˆ Performance Tips

1. **Start with successful sites**: QuietLight, BizQuest, WebsiteProperties
2. **Use `--max-listings`**: Test with small batches first
3. **Monitor logs**: Check for 500 errors or timeouts
4. **Database queries**: Use SQLite browser to explore data

## ğŸ› Troubleshooting

- **500 Errors**: Site is blocking ScraperAPI, try different site
- **No listings found**: Check site structure may have changed
- **Import errors**: Ensure all dependencies are installed
- **Database locked**: Close other connections to SQLite

## ğŸ“ License

This project is for educational purposes. Respect website terms of service and robots.txt files.