# Business Listing Scraper

A clean, modular web scraper for business listings from multiple marketplace websites using ScraperAPI.

## ğŸ“‹ Features

- **9 Marketplace Scrapers**: QuietLight, BizBuySell, BizQuest, WebsiteProperties, Flippa, EmpireFlippers, Acquire, FE International, WebsiteClosers
- **Database Storage**: Google BigQuery (no local database files)
- **ScraperAPI Integration**: Bypass anti-scraping measures
- **Amazon FBA Detection**: Automatic identification of Amazon FBA businesses
- **Enhanced Detail Scraping**: Fetch additional details from listing pages
- **Data Analysis Tools**: Comprehensive analytics and reporting
- **Modular Architecture**: Easy to add new sites
- **Comprehensive Data**: Price, revenue, cash flow, EBITDA, location, industry, and more
- **Automatic Deduplication**: Based on listing URL

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone the repository
git clone <your-repo-url>
cd biz-scraper-clean

# Install dependencies
pip install -r requirements.txt
```

### 2. Configuration

```bash
# Copy environment file
cp .env.example .env

# Edit .env and add your ScraperAPI key
# Get your key at: https://www.scraperapi.com/
```

### 3. Run the Scraper

```bash
# Run all sites
python main.py

# Run specific sites
python main.py --sites QuietLight BizQuest

# Limit listings per site
python main.py --max-listings 50

# Or use the runner script
./run_scraper.sh --sites QuietLight --max-listings 10
```

## ğŸ“Š Supported Sites

| Site | Success Rate | Notes |
|------|-------------|-------|
| **QuietLight** | â­â­â­â­â­ | Best performer, high-value listings ($1M-$17M) |
| **BizQuest** | â­â­â­â­ | Good for small-medium businesses |
| **WebsiteProperties** | â­â­â­â­ | Digital businesses, SaaS focused |
| **Acquire.com** | â­â­â­ | Startups and SaaS acquisitions |
| **FE International** | â­â­â­ | Premium online business broker |
| **WebsiteClosers** | â­â­â­ | Established online businesses |
| **BizBuySell** | â­â­ | Individual pages may fail (anti-scraping) |
| **Flippa** | â­â­ | JavaScript-heavy, limited success |
| **EmpireFlippers** | â­â­ | JavaScript-heavy, needs different approach |

## ğŸ—„ï¸ Database Schema

The BigQuery database stores:

- **Basic Info**: title, source_site, listing_url
- **Financials**: price, revenue, cash_flow, multiple, ebitda, inventory_value
- **Details**: location, industry, established_year, employees, website
- **Features**: seller_financing, reason_for_selling, monthly_traffic
- **Amazon FBA**: is_amazon_fba, amazon_business_type
- **Metadata**: scraped_at, updated_at, enhanced_at

## ğŸ—ï¸ Project Structure

```
biz-scraper-clean/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py          # ScraperAPI config & site definitions
â”œâ”€â”€ bigquery/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ client.py            # BigQuery client and operations
â”œâ”€â”€ logs/                    # Log files (auto-generated)
â”œâ”€â”€ test_files/              # HTML test files
â”œâ”€â”€ temp/                    # Temporary scripts and files
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_scraper.py      # Abstract base class
â”‚   â”œâ”€â”€ bizbuysell_scraper.py
â”‚   â”œâ”€â”€ bizquest_scraper.py
â”‚   â”œâ”€â”€ flippa_scraper.py
â”‚   â”œâ”€â”€ quietlight_scraper.py
â”‚   â”œâ”€â”€ websiteproperties_scraper.py
â”‚   â”œâ”€â”€ empireflippers_scraper.py
â”‚   â”œâ”€â”€ acquire_scraper.py
â”‚   â”œâ”€â”€ feinternational_scraper.py
â”‚   â””â”€â”€ websiteclosers_scraper.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ amazon_detector.py   # Amazon FBA detection
â”œâ”€â”€ .env.example             # Environment template
â”œâ”€â”€ .gitignore              # Git ignore rules
â”œâ”€â”€ main.py                 # Entry point
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ run_scraper.sh         # Convenience runner
â”œâ”€â”€ test_all_sites.py      # Test suite
â””â”€â”€ README.md              # This file
```

## ğŸ” Additional Features

### Amazon FBA Detection
The scraper automatically detects Amazon FBA businesses using keyword analysis:
```bash
# Results include is_amazon_fba and amazon_business_type fields
```


### Data Analysis
Query data directly in BigQuery console or using bq CLI:
```bash
# Count listings by source
bq query --use_legacy_sql=false \
"SELECT source_site, COUNT(*) as count 
FROM business_listings.businesses_all_sites_view 
GROUP BY source_site"

# Find high-value listings
bq query --use_legacy_sql=false \
"SELECT title, price, source_site 
FROM business_listings.businesses_all_sites_view 
WHERE price > 1000000 
ORDER BY price DESC"
```

## ğŸ§ª Testing

```bash
# Test all sites individually
python test_all_sites.py

# This will:
# - Test search page access
# - Attempt to scrape one listing
# - Save to database
# - Report success/failure for each site
```

## ğŸ”§ Adding a New Site

1. Create a new scraper in `scrapers/` inheriting from `BaseScraper`
2. Implement `get_listing_urls()` and `scrape_listing()` methods
3. Add site config to `config/settings.py`
4. Add scraper class to `main.py`

Example:
```python
from scrapers.base_scraper import BaseScraper

class NewSiteScraper(BaseScraper):
    def get_listing_urls(self, max_pages=None):
        # Implementation
        pass
    
    def scrape_listing(self, url):
        # Implementation
        pass
```

## âš ï¸ Important Notes

- **API Limits**: ScraperAPI has request limits based on your plan
- **Rate Limiting**: The scraper includes delays to be respectful
- **Anti-Scraping**: Some sites (BizBuySell) have strong protections
- **Data Quality**: Not all fields will be available for every listing

## ğŸ“ˆ Performance Tips

1. **Start with successful sites**: QuietLight, BizQuest, WebsiteProperties
2. **Use `--max-listings`**: Test with small batches first
3. **Monitor logs**: Check for 500 errors or timeouts
4. **Database queries**: Use BigQuery console or bq CLI to explore data

## ğŸ› Troubleshooting

- **500 Errors**: Site is blocking ScraperAPI, try different site
- **No listings found**: Check site structure may have changed
- **Import errors**: Ensure all dependencies are installed
- **BigQuery permissions**: Ensure proper GCP credentials are configured

## ğŸ“ License

This project is for educational purposes. Respect website terms of service and robots.txt files.